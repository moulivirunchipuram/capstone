{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "* The goal of this project is to enable data analysts and other similar parties analyze various aspects of immigration data, by collecting data from four different data sets viz.,immigration, airport codes, US Cities demographics and global temperature.  The project builds a useful schema from these datasets which will enable analysts to get an information like which origin country has more visitors visiting US, how long do they stay in the US, what's the demography of the state where the immigrants land in, and what's the average temparature of the country\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import necessary libraries and user defined utilities\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import configparser\n",
    "import datetime as dt\n",
    "import time\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear, avg, monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import year, month, dayofmonth, weekofyear, date_format\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData, HiveContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import date_add as d_add\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import Row\n",
    "import util as util\n",
    "import table_helper as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "immigration_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "immigration_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Global Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "global_temperature_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_temperature_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_temperature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_temperature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " #### AIRPORT CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55075, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_codes_csv = 'airport-codes_csv.csv'\n",
    "airport_codes_df = pd.read_csv(airport_codes_csv)\n",
    "airport_codes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing rows with null values for ['iata_code', 'local_code']\n",
      "total rows before clean up 55075\n",
      "total rows after clean up 2987\n"
     ]
    }
   ],
   "source": [
    "column_list = ['iata_code', 'local_code']\n",
    "airport_codes_df = util.cleanup_missing_column_values(airport_codes_df,column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_codes_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_codes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US CITY DEMOGRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City     State  Median Age  Male Population  Female Population  \\\n",
       "0  Silver Spring  Maryland        33.8          40601.0            41862.0   \n",
       "\n",
       "   Total Population  Number of Veterans  Foreign-born  Average Household Size  \\\n",
       "0             82463              1562.0       30908.0                     2.6   \n",
       "\n",
       "  State Code                Race  Count  \n",
       "0         MD  Hispanic or Latino  25924  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_dem_csv = \"us-cities-demographics.csv\"\n",
    "demographics_df = pd.read_csv(us_cities_dem_csv, delimiter=';')\n",
    "demographics_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column Male Population has null value\n",
      "column Female Population has null value\n",
      "column Number of Veterans has null value\n",
      "column Foreign-born has null value\n",
      "column Average Household Size has null value\n",
      "finished checking for null\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for column in demographics_df:\n",
    "    values = demographics_df[column].unique()\n",
    "    if(True in pd.isnull(values)):\n",
    "        print(f\"column {column} has null value\")\n",
    "print(\"finished checking for null\")        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Build country code to country name data frame \n",
    "_(The following code is used based on a direction from a mentor)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code      country\n",
       "0  236  AFGHANISTAN\n",
       "1  101      ALBANIA\n",
       "2  316      ALGERIA\n",
       "3  102      ANDORRA\n",
       "4  324       ANGOLA"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract country name and country code from I94_SAS_Labels_Descriptions.SAS\n",
    "\n",
    "with open(\"I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    contents = f.readlines()\n",
    "    country_code = {}\n",
    "    for countries in contents[10:298]:\n",
    "        pair = countries.split('=')\n",
    "        code,country = pair[0].strip(), pair[1].strip().strip(\"'\")\n",
    "        country_code[code] = country\n",
    "country_code_df = pd.DataFrame(list(country_code.items()),columns=['code','country'])\n",
    "country_code_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "* Clean up data with null values in important columns\n",
    "* Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_spark = immigration_spark.drop(\"insnum\",\"occup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up Immigration data\n",
    "immigration_spark = immigration_spark.where(immigration_spark.arrdate.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_spark = immigration_spark.where(immigration_spark.depdate.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up Global Temperature data\n",
    "global_temperature_df = global_temperature_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_temperature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding historical data and work with data for recent 20 years\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(576080, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#discard historical data and work with data for past 20 years\n",
    "print(\"Discarding historical data and work with data for recent 20 years\")\n",
    "dt_begin = \"2000-01-01\"\n",
    "dt_end = \"2019-01-01\"\n",
    "after_dt_begin = global_temperature_df[\"dt\"] >= dt_begin\n",
    "before_dt_end = global_temperature_df[\"dt\"] < dt_end\n",
    "dt_range = after_dt_begin & before_dt_end\n",
    "global_temperature_df = global_temperature_df.loc[dt_range]\n",
    "global_temperature_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing rows with null values for ['iata_code', 'local_code']\n",
      "total rows before clean up 2987\n",
      "total rows after clean up 2987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2987, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up Airport codes\n",
    "column_list = ['iata_code', 'local_code']\n",
    "airport_codes_df = util.cleanup_missing_column_values(airport_codes_df,column_list)\n",
    "airport_codes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2875, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df = demographics_df.drop_duplicates()\n",
    "demographics_df = demographics_df.dropna()\n",
    "# need to remove rows that have null values for the following columns\n",
    "# Male Population, Female Population\n",
    "# column_list = ['Male Population', 'Female Population',]\n",
    "# demographics_df = util.cleanup_missing_column_values(demographics_df,column_list)\n",
    "demographics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "* The process of admitting a visitor to the US triggers events that can be classifed as facts.  In this project we are creating immigration fact table\n",
    "* Derive dimension tables\n",
    "    * airport\n",
    "    * time\n",
    "    * status\n",
    "    * visa\n",
    "    * temperature\n",
    "    * country\n",
    "    * state\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "* Load data into staging environment\n",
    "* Create fact and dimension tables\n",
    "* Write table data into parquet files\n",
    "* Run data quality tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# not including insnum, occup columns as majority of rows contain null value for these columns\n",
    "# also these columns are dropped from the data frame\n",
    "# immig_schema = StructType([StructField(\"0\", IntegerType(), True)\\\n",
    "#                           ,StructField(\"cicid\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94yr\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94mon\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94cit\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94res\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94port\", StringType(), True)\\\n",
    "#                           ,StructField(\"arrdate\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94mode\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94addr\", StringType(), True)\\\n",
    "#                           ,StructField(\"depdate\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94bir\", FloatType(), True)\\\n",
    "#                           ,StructField(\"i94visa\", FloatType(), True)\\\n",
    "#                           ,StructField(\"count\", FloatType(), True)\\\n",
    "#                           ,StructField(\"dtadfile\", StringType(), True)\\\n",
    "#                           ,StructField(\"visapost\", StringType(), True)\\\n",
    "#                           ,StructField(\"entdepa\", StringType(), True)\\\n",
    "#                           ,StructField(\"entdepd\", StringType(), True)\\\n",
    "#                           ,StructField(\"entdepu\", StringType(), True)\\\n",
    "#                           ,StructField(\"matflag\", StringType(), True)\\\n",
    "#                           ,StructField(\"biryear\", FloatType(), True)\\\n",
    "#                           ,StructField(\"dtaddto\", StringType(), True)\\\n",
    "#                           ,StructField(\"gender\", StringType(), True)\\\n",
    "#                           ,StructField(\"airline\", StringType(), True)\\\n",
    "#                           ,StructField(\"admnum\", FloatType(), True)\\\n",
    "#                           ,StructField(\"fltno\", StringType(), True)\\\n",
    "#                           ,StructField(\"visatype\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# immigration_spark = spark.createDataFrame(immigration_df, schema=immig_schema)\n",
    "print(immigration_spark.count(),len(immigration_spark.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>3.065</td>\n",
       "      <td>0.372</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>3.724</td>\n",
       "      <td>0.241</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>3.976</td>\n",
       "      <td>0.296</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>8.321</td>\n",
       "      <td>0.221</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>13.567</td>\n",
       "      <td>0.253</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  average_temperature  average_temperature_uncertainty   city  \\\n",
       "0  2000-01-01                3.065                            0.372  Århus   \n",
       "1  2000-02-01                3.724                            0.241  Århus   \n",
       "2  2000-03-01                3.976                            0.296  Århus   \n",
       "3  2000-04-01                8.321                            0.221  Århus   \n",
       "4  2000-05-01               13.567                            0.253  Århus   \n",
       "\n",
       "   country latitude longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globaltemp_schema = StructType([StructField(\"dt\", StringType(), True)\\\n",
    "                          ,StructField(\"average_temperature\", FloatType(), True)\\\n",
    "                          ,StructField(\"average_temperature_uncertainty\", FloatType(), True)\\\n",
    "                          ,StructField(\"city\", StringType(), True)\\\n",
    "                          ,StructField(\"country\", StringType(), True)\\\n",
    "                          ,StructField(\"latitude\", StringType(), True)\\\n",
    "                          ,StructField(\"longitude\", StringType(), True)])\n",
    "global_temperature_df.rename(columns={'AverageTemperature':'average_temperature'}, inplace=True)\n",
    "global_temperature_df.rename(columns={'AverageTemperatureUncertainty':'average_temperature_uncertainty'}, inplace=True)\n",
    "global_temperature_df.rename(columns={'City':'city'}, inplace=True)\n",
    "global_temperature_df.rename(columns={'Country':'country'}, inplace=True)\n",
    "global_temperature_df.rename(columns={'Latitude':'latitude'}, inplace=True)\n",
    "global_temperature_df.rename(columns={'Longitude':'longitude'}, inplace=True)\n",
    "\n",
    "temp_spark = spark.createDataFrame(global_temperature_df, schema=globaltemp_schema)\n",
    "\n",
    "temp_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_spark.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.799999</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.599998</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland   33.799999          40601.0   \n",
       "1            Quincy  Massachusetts   41.000000          44129.0   \n",
       "2            Hoover        Alabama   38.500000          38040.0   \n",
       "3  Rancho Cucamonga     California   34.500000          88127.0   \n",
       "4            Newark     New Jersey   34.599998         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_schema = StructType([StructField(\"City\", StringType(), True)\\\n",
    "                        ,StructField(\"State\", StringType(), True)\\\n",
    "                        ,StructField(\"Median Age\", FloatType(), True)\\\n",
    "                        ,StructField(\"Male Population\", FloatType(), True)\\\n",
    "                        ,StructField(\"Female Population\", FloatType(), True)\\\n",
    "                        ,StructField(\"Total Population\", IntegerType(), True)\\\n",
    "                        ,StructField(\"Number of Veterans\", FloatType(), True)\\\n",
    "                        ,StructField(\"Foreign-born\", FloatType(), True)\\\n",
    "                        ,StructField(\"Average Household Size\", FloatType(), True)\\\n",
    "                        ,StructField(\"State Code\", StringType(), True)\\\n",
    "                        ,StructField(\"Race\", StringType(), True)\\\n",
    "                        ,StructField(\"Count\", IntegerType(), True)])\n",
    "\n",
    "dem_spark = spark.createDataFrame(demographics_df, schema=dem_schema)\n",
    "\n",
    "dem_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03N</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Utirik Airport</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OC</td>\n",
       "      <td>MH</td>\n",
       "      <td>MH-UTI</td>\n",
       "      <td>Utirik Island</td>\n",
       "      <td>K03N</td>\n",
       "      <td>UTK</td>\n",
       "      <td>03N</td>\n",
       "      <td>169.852005, 11.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803161621, 25.325399398804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PQS</td>\n",
       "      <td>0AK</td>\n",
       "      <td>-162.899994, 61.934601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>8980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>CSE</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>-106.928341, 38.851918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>JCY</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>-98.62249755859999, 30.251800537100003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                     name  elevation_ft continent  \\\n",
       "0   03N  small_airport           Utirik Airport           4.0        OC   \n",
       "1  07FA  small_airport  Ocean Reef Club Airport           8.0       NaN   \n",
       "2   0AK  small_airport    Pilot Station Airport         305.0       NaN   \n",
       "3  0CO2  small_airport    Crested Butte Airpark        8980.0       NaN   \n",
       "4  0TE7  small_airport        LBJ Ranch Airport        1515.0       NaN   \n",
       "\n",
       "  iso_country iso_region   municipality gps_code iata_code local_code  \\\n",
       "0          MH     MH-UTI  Utirik Island     K03N       UTK        03N   \n",
       "1          US      US-FL      Key Largo     07FA       OCA       07FA   \n",
       "2          US      US-AK  Pilot Station      NaN       PQS        0AK   \n",
       "3          US      US-CO  Crested Butte     0CO2       CSE       0CO2   \n",
       "4          US      US-TX   Johnson City     0TE7       JCY       0TE7   \n",
       "\n",
       "                              coordinates  \n",
       "0                      169.852005, 11.222  \n",
       "1       -80.274803161621, 25.325399398804  \n",
       "2                  -162.899994, 61.934601  \n",
       "3                  -106.928341, 38.851918  \n",
       "4  -98.62249755859999, 30.251800537100003  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_schema =  StructType([StructField(\"ident\", StringType(), True)\\\n",
    "                        ,StructField(\"type\", StringType(), True)\\\n",
    "                        ,StructField(\"name\", StringType(), True)\\\n",
    "                        ,StructField(\"elevation_ft\", FloatType(), True)\\\n",
    "                        ,StructField(\"continent\", StringType(), True)\\\n",
    "                        ,StructField(\"iso_country\", StringType(), True)\\\n",
    "                        ,StructField(\"iso_region\", StringType(), True)\\\n",
    "                        ,StructField(\"municipality\", StringType(), True)\\\n",
    "                        ,StructField(\"gps_code\", StringType(), True)\\\n",
    "                        ,StructField(\"iata_code\", StringType(), True)\\\n",
    "                        ,StructField(\"local_code\", StringType(), True)\\\n",
    "                        ,StructField(\"coordinates\", StringType(), True)])\n",
    "airport_spark = spark.createDataFrame(airport_codes_df, schema=airport_schema)\n",
    "\n",
    "airport_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Define output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_path=\"table_data2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1.Create airport dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table airport to table_data2/airport\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "airport_spark = helper.create_airport(airport_spark, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2.Create time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table time to table_data2/time\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "time = helper.create_time(immigration_spark,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3.Create status dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table status to table_data2/status\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "status = helper.create_status(immigration_spark,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.Create visa dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table visa to table_data2/visa\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "visa = helper.create_visa(immigration_spark,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_temperature(input_df, output_path):\n",
    "    \"\"\"\n",
    "        Gather temperature data, create dataframe and write data into parquet files.\n",
    "        \n",
    "        :param input_df: dataframe of input data.\n",
    "        :param output_data: path to write data to.\n",
    "        :return: dataframe representing temperature dimension\n",
    "    \"\"\"\n",
    "    print(\"creating temperature table data\")\n",
    "    output_df = input_df.groupBy(\"country\").agg(\n",
    "                round(mean('average_temperature'),1).alias(\"average_temperature\"),\\\n",
    "                round(mean(\"average_temperature_uncertainty\"),1).alias(\"average_temperature_uncertainty\")\n",
    "            ).dropna()\\\n",
    "            .withColumn(\"temperature_id\", monotonically_increasing_id()) \\\n",
    "            .select([\"temperature_id\", \"country\", \"average_temperature\", \"average_temperature_uncertainty\"])\n",
    "    \n",
    "    util.output_to_parquet_file(output_df, output_path, \"temperature\")\n",
    "    \n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.Create temperature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating temperature table data\n",
      "Writing table temperature to table_data2/temperature\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "temperature = create_temperature(temp_spark,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 6.Create country dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_spark = spark.createDataFrame(country_code_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table country to table_data2/country\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "country = helper.create_country(country_spark,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 9.Create state dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_state(input_df, output_path):\n",
    "    \"\"\"\n",
    "        Get state specific data and create dataframe and write data into parquet files.\n",
    "        Here we will group the information by state code\n",
    "        Rename the columns from Xxxx Yyyy to xxx_yyy\n",
    "        Drop rows with null values\n",
    "        \n",
    "        :param input_df: dataframe of input data.\n",
    "        :param output_data: path to write data to.\n",
    "        :return: dataframe representing state dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    output_df = input_df.select([\"State Code\", \"State\", \"Median Age\", \"Male Population\", \"Female Population\", \"Total Population\", \"Average Household Size\",\\\n",
    "                          \"Foreign-born\", \"Race\", \"Count\"])\\\n",
    "                .withColumnRenamed(\"State\",\"state\")\\\n",
    "                .withColumnRenamed(\"State Code\", \"state_code\")\\\n",
    "                .withColumnRenamed(\"Median Age\", \"median_age\")\\\n",
    "                .withColumnRenamed(\"Male Population\", \"male_population\")\\\n",
    "                .withColumnRenamed(\"Female Population\", \"female_population\")\\\n",
    "                .withColumnRenamed(\"Total Population\", \"total_population\")\\\n",
    "                .withColumnRenamed(\"Average Household Size\", \"avg_household_size\")\\\n",
    "                .withColumnRenamed(\"Foreign-born\", \"foreign_born\")\\\n",
    "                .withColumnRenamed(\"Race\", \"race\")\\\n",
    "                .withColumnRenamed(\"Count\", \"count\")\n",
    "    print(output_df.show(2))\n",
    "    output_df = output_df.groupBy(\"state_code\",\"state\").agg(\\\n",
    "                round(mean('median_age'),0).alias(\"median_age\"),\\\n",
    "                sum(\"total_population\").alias(\"total_population\"),\\\n",
    "                sum(\"male_population\").alias(\"male_population\"),\\\n",
    "                sum(\"female_population\").alias(\"female_population\"),\\\n",
    "                sum(\"foreign_born\").alias(\"foreign_born\"), \\\n",
    "                sum(\"avg_household_size\").alias(\"average_household_size\")\n",
    "                ).dropna()\n",
    "    \n",
    "    util.output_to_parquet_file(output_df, output_path, \"state\")\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+-----+\n",
      "|state_code|        state|median_age|male_population|female_population|total_population|avg_household_size|foreign_born|              race|count|\n",
      "+----------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+-----+\n",
      "|        MD|     Maryland|      33.8|        40601.0|          41862.0|           82463|               2.6|     30908.0|Hispanic or Latino|25924|\n",
      "|        MA|Massachusetts|      41.0|        44129.0|          49500.0|           93629|              2.39|     32935.0|             White|58723|\n",
      "+----------+-------------+----------+---------------+-----------------+----------------+------------------+------------+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n",
      "Writing table state to table_data2/state\n",
      "Write complete!\n"
     ]
    }
   ],
   "source": [
    "state = create_state(dem_spark,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create Immigration Fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# join city dimension and temperature dimension\n",
    "country_temperature = country.select([\"*\"])\\\n",
    "            .join(temperature, (country.country == upper(temperature.country)), how='full')\\\n",
    "            .select([country.code, country.country, temperature.temperature_id, temperature.average_temperature, temperature.average_temperature_uncertainty])\n",
    "\n",
    "country_temperature.write.mode(\"overwrite\").parquet(output_path+\"country_temperature_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration = helper.create_immigration(immigration_spark, output_path, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create a temp view - immigration_view\n",
    "immigration.createOrReplaceTempView(\"immigration_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- ident: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- temperature_id: long (nullable = true)\n",
      " |-- status_flag_id: long (nullable = true)\n",
      " |-- visa_id: long (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- foreign_born: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_states = immigration.groupBy(\"state_code\").count().persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_states.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_state_foreign_born = spark.sql(\"select distinct state_code, foreign_born from immigration_view where foreign_born > 100 order by foreign_born desc\").persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- foreign_born: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_state_foreign_born.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_state_foreign_born.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1. Generic data check\n",
    "\n",
    "_In this section, top 5 rows are printed form each of the dimension and fact tables_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport = spark.read.parquet(output_path+\"airport\")\n",
    "#airport.toPandas().head()\n",
    "airport.toPandas().dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time = spark.read.parquet(output_path+\"time\")\n",
    "#time.toPandas().head()\n",
    "time.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "status = spark.read.parquet(output_path+\"status\")\n",
    "#status.toPandas().head()\n",
    "status.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa = spark.read.parquet(output_path+\"visa\")\n",
    "#visa.toPandas().head()\n",
    "visa.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature = spark.read.parquet(output_path+\"temperature\")\n",
    "#temperature.toPandas().head()\n",
    "temperature.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country = spark.read.parquet(output_path+\"country\")\n",
    "#country.toPandas().head()\n",
    "country.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state = spark.read.parquet(output_path+\"state\")\n",
    "#state.toPandas().head()\n",
    "state.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_temperature = spark.read.parquet(output_path+\"country_temperature_mapping\")\n",
    "country_temperature.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration = spark.read.parquet(output_path+\"immigration\")\n",
    "#immigration.toPandas().head()\n",
    "immigration.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. Record count check\n",
    "##### _In this section, a generic record count is done for each table_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.run_record_count_check(airport, \"airport\")\n",
    "util.run_record_count_check(time, \"time\")\n",
    "util.run_record_count_check(status, \"status\")\n",
    "util.run_record_count_check(visa, \"visa\")\n",
    "util.run_record_count_check(state, \"state\")\n",
    "util.run_record_count_check(temperature, \"temperature\")\n",
    "util.run_record_count_check(immigration, \"immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. Custom data check\n",
    "_In this section, results for custom queries are printed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Get total count of immigrants for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "imm_df = immigration.toPandas()\n",
    "imm_df = imm_df.groupby(['country'])['country'].count()\n",
    "imm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "__Please refer Data Dictionary.ipynb file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.1 Rationale for the choice of tools and technologies for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Used Apache Spark, so that we can take advantage of Spark's feature of caching data in memory and also parallel processing.\n",
    "* Used Pandas data frames for convenience in data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.2 How often the data should be updated/refreshed, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* From the project's perspective, it depends on how often the immigration dataset gets updated as the data on other dimension tables depneds on immigration data.  If the immigration data gets updated on a monthly basis, then all other data should be updated monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 5.3 Approach in different scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### a. If the data is increased by 100x\n",
    "* I would have to use frameworks like Amazon Redshift, EMR Cluster etc to handle such a magnitude of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### b. If the data populates a dashboard that needs to be updated by 7am daily\n",
    "* In this case, I would use Apache Airflow DAG which facilitates scheduling building/managing data pipelines on a timely basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "###### c. If 100+ people are going to access the system\n",
    "* In this case I would have to use a tried and tested set up like Amazon Redshift, Snowflakes and few other similar setup which are known to handle high database traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
